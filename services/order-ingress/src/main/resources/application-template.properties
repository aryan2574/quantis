# ==================== APPLICATION TEMPLATE ====================
# Template for Spring Boot application configuration (Properties format)
# Copy this file to application.properties and customize for your service
# Remove or comment out sections you don't need

# ==================== SERVER CONFIGURATION ====================
# HTTP server configuration
server.port=8080
server.servlet.context-path=/
server.compression.enabled=true
server.compression.mime-types=application/json,application/xml,text/html,text/xml,text/plain
server.error.include-message=always
server.error.include-binding-errors=always

# ==================== SPRING APPLICATION CONFIGURATION ====================
# Application metadata
spring.application.name=service-name
spring.profiles.active=dev

# ==================== KAFKA CONFIGURATION ====================
# Kafka cluster connection
spring.kafka.bootstrap-servers=localhost:9092

# Producer configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.retries=3
spring.kafka.producer.acks=all
spring.kafka.producer.batch-size=16384
spring.kafka.producer.linger-ms=1
spring.kafka.producer.buffer-memory=33554432
spring.kafka.producer.enable-idempotence=true
spring.kafka.producer.compression-type=snappy

# Consumer configuration
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.group-id=${spring.application.name}-consumer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=1000
spring.kafka.consumer.max-poll-records=500
spring.kafka.consumer.max-poll-interval-ms=300000
spring.kafka.consumer.session-timeout-ms=30000
spring.kafka.consumer.heartbeat-interval-ms=3000

# ==================== DATABASE CONFIGURATION ====================
# PostgreSQL Configuration
spring.datasource.url=jdbc:postgresql://localhost:5432/quantisdb
spring.datasource.username=quantis
spring.datasource.password=quantis
spring.datasource.driver-class-name=org.postgresql.Driver

# HikariCP connection pool
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.batch_size=20
spring.jpa.properties.hibernate.jdbc.fetch_size=20

# ==================== REDIS CONFIGURATION ====================
spring.redis.host=localhost
spring.redis.port=6379
spring.redis.timeout=2000ms
spring.redis.lettuce.pool.max-active=8
spring.redis.lettuce.pool.max-idle=8
spring.redis.lettuce.pool.min-idle=0
spring.redis.lettuce.pool.max-wait=-1ms

# ==================== ELASTICSEARCH CONFIGURATION ====================
spring.elasticsearch.uris=http://localhost:9200
spring.elasticsearch.connection-timeout=1s
spring.elasticsearch.socket-timeout=30s

# ==================== CASSANDRA CONFIGURATION ====================
spring.data.cassandra.contact-points=localhost
spring.data.cassandra.port=9042
spring.data.cassandra.keyspace-name=quantis
spring.data.cassandra.local-datacenter=datacenter1
spring.data.cassandra.schema-action=validate
spring.data.cassandra.request-timeout=10s
spring.data.cassandra.connect-timeout=10s

# ==================== MANAGEMENT ENDPOINTS ====================
# Spring Boot Actuator configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoints.web.base-path=/actuator
management.endpoint.health.show-details=when-authorized
management.endpoint.health.show-components=always
management.endpoint.metrics.enabled=true
management.metrics.export.prometheus.enabled=true

# ==================== LOGGING CONFIGURATION ====================
# Logging levels
logging.level.root=INFO
logging.level.com.quantis=DEBUG
logging.level.org.springframework.kafka=INFO
logging.level.org.apache.kafka=INFO
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

# Logging patterns
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# Logging files
logging.file.name=logs/${spring.application.name}.log
logging.file.max-size=10MB
logging.file.max-history=30

# ==================== SECURITY CONFIGURATION ====================
# JWT Configuration
jwt.secret=your-jwt-secret-key-here-change-in-production
jwt.expiration=86400000

# ==================== TRADING PLATFORM SPECIFIC ====================
# Order processing
trading.order.max-quantity=1000000
trading.order.min-quantity=1
trading.order.max-price=1000000.0
trading.order.min-price=0.01
trading.order.allowed-symbols=AAPL,GOOGL,MSFT,TSLA,AMZN,META,NVDA,NFLX

# Risk management
trading.risk.max-order-value=1000000.0
trading.risk.max-daily-volume=10000000.0
trading.risk.position-limits.enabled=true
trading.risk.position-limits.max-position-size=100000

# Market data
trading.market-data.refresh-interval=1000
trading.market-data.cache-ttl=5000

# ==================== CACHE CONFIGURATION ====================
# Caffeine cache configuration
caffeine.cache.default.maximum-size=1000
caffeine.cache.default.expire-after-write=5m
caffeine.cache.orders.maximum-size=10000
caffeine.cache.orders.expire-after-write=1h
caffeine.cache.market-data.maximum-size=1000
caffeine.cache.market-data.expire-after-write=1s

# ==================== SCHEDULING ====================
# Task scheduling configuration
scheduling.pool-size=5
scheduling.thread-name-prefix=scheduled-task-

# ==================== MONITORING ====================
# Micrometer configuration for metrics
management.metrics.tags.application=${spring.application.name}
management.metrics.tags.environment=${spring.profiles.active}
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.distribution.percentiles.http.server.requests=0.5,0.95,0.99

# ==================== ENVIRONMENT VARIABLES ====================
# These can be overridden by environment variables
# Example: export SERVER_PORT=8081 or export SPRING_PROFILES_ACTIVE=prod

# ==================== DEVELOPMENT PROFILE ====================
# Uncomment and modify for development environment
#spring.config.activate.on-profile=dev
#spring.jpa.show-sql=true
#spring.jpa.hibernate.ddl-auto=create-drop
#logging.level.com.quantis=DEBUG
#logging.level.org.springframework=DEBUG

# ==================== PRODUCTION PROFILE ====================
# Uncomment and modify for production environment
#spring.config.activate.on-profile=prod
#spring.jpa.show-sql=false
#spring.jpa.hibernate.ddl-auto=validate
#logging.level.com.quantis=INFO
#logging.level.org.springframework=WARN
#logging.level.root=WARN

# ==================== CUSTOM PROPERTIES ====================
# Add your custom application properties here
# Example:
# app.feature.enabled=true
# app.api.version=v1
# app.timeout=5000
